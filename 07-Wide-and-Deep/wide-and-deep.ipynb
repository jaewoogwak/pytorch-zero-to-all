{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim, from_numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's shape: torch.Size([759, 8]) | Y's shape: torch.Size([759, 1])\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('../data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
    "x_data = from_numpy(xy[:, 0:-1])\n",
    "y_data = from_numpy(xy[:, [-1]])\n",
    "print(f'X\\'s shape: {x_data.shape} | Y\\'s shape: {y_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(8,6)\n",
    "        self.l2 = nn.Linear(6,4)\n",
    "        self.l3 = nn.Linear(4,1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = nn.BCELoss(reduction='mean')\n",
    "optimzier = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 | Loss:0.6627\n",
      "Epoch: 2/100 | Loss:0.6610\n",
      "Epoch: 3/100 | Loss:0.6594\n",
      "Epoch: 4/100 | Loss:0.6580\n",
      "Epoch: 5/100 | Loss:0.6568\n",
      "Epoch: 6/100 | Loss:0.6557\n",
      "Epoch: 7/100 | Loss:0.6547\n",
      "Epoch: 8/100 | Loss:0.6538\n",
      "Epoch: 9/100 | Loss:0.6529\n",
      "Epoch: 10/100 | Loss:0.6522\n",
      "Epoch: 11/100 | Loss:0.6515\n",
      "Epoch: 12/100 | Loss:0.6510\n",
      "Epoch: 13/100 | Loss:0.6504\n",
      "Epoch: 14/100 | Loss:0.6499\n",
      "Epoch: 15/100 | Loss:0.6495\n",
      "Epoch: 16/100 | Loss:0.6491\n",
      "Epoch: 17/100 | Loss:0.6488\n",
      "Epoch: 18/100 | Loss:0.6484\n",
      "Epoch: 19/100 | Loss:0.6482\n",
      "Epoch: 20/100 | Loss:0.6479\n",
      "Epoch: 21/100 | Loss:0.6477\n",
      "Epoch: 22/100 | Loss:0.6475\n",
      "Epoch: 23/100 | Loss:0.6473\n",
      "Epoch: 24/100 | Loss:0.6471\n",
      "Epoch: 25/100 | Loss:0.6469\n",
      "Epoch: 26/100 | Loss:0.6468\n",
      "Epoch: 27/100 | Loss:0.6467\n",
      "Epoch: 28/100 | Loss:0.6466\n",
      "Epoch: 29/100 | Loss:0.6464\n",
      "Epoch: 30/100 | Loss:0.6464\n",
      "Epoch: 31/100 | Loss:0.6463\n",
      "Epoch: 32/100 | Loss:0.6462\n",
      "Epoch: 33/100 | Loss:0.6461\n",
      "Epoch: 34/100 | Loss:0.6461\n",
      "Epoch: 35/100 | Loss:0.6460\n",
      "Epoch: 36/100 | Loss:0.6460\n",
      "Epoch: 37/100 | Loss:0.6459\n",
      "Epoch: 38/100 | Loss:0.6459\n",
      "Epoch: 39/100 | Loss:0.6458\n",
      "Epoch: 40/100 | Loss:0.6458\n",
      "Epoch: 41/100 | Loss:0.6458\n",
      "Epoch: 42/100 | Loss:0.6457\n",
      "Epoch: 43/100 | Loss:0.6457\n",
      "Epoch: 44/100 | Loss:0.6457\n",
      "Epoch: 45/100 | Loss:0.6457\n",
      "Epoch: 46/100 | Loss:0.6456\n",
      "Epoch: 47/100 | Loss:0.6456\n",
      "Epoch: 48/100 | Loss:0.6456\n",
      "Epoch: 49/100 | Loss:0.6456\n",
      "Epoch: 50/100 | Loss:0.6456\n",
      "Epoch: 51/100 | Loss:0.6456\n",
      "Epoch: 52/100 | Loss:0.6456\n",
      "Epoch: 53/100 | Loss:0.6455\n",
      "Epoch: 54/100 | Loss:0.6455\n",
      "Epoch: 55/100 | Loss:0.6455\n",
      "Epoch: 56/100 | Loss:0.6455\n",
      "Epoch: 57/100 | Loss:0.6455\n",
      "Epoch: 58/100 | Loss:0.6455\n",
      "Epoch: 59/100 | Loss:0.6455\n",
      "Epoch: 60/100 | Loss:0.6455\n",
      "Epoch: 61/100 | Loss:0.6455\n",
      "Epoch: 62/100 | Loss:0.6455\n",
      "Epoch: 63/100 | Loss:0.6455\n",
      "Epoch: 64/100 | Loss:0.6455\n",
      "Epoch: 65/100 | Loss:0.6455\n",
      "Epoch: 66/100 | Loss:0.6455\n",
      "Epoch: 67/100 | Loss:0.6455\n",
      "Epoch: 68/100 | Loss:0.6455\n",
      "Epoch: 69/100 | Loss:0.6455\n",
      "Epoch: 70/100 | Loss:0.6455\n",
      "Epoch: 71/100 | Loss:0.6455\n",
      "Epoch: 72/100 | Loss:0.6455\n",
      "Epoch: 73/100 | Loss:0.6454\n",
      "Epoch: 74/100 | Loss:0.6454\n",
      "Epoch: 75/100 | Loss:0.6454\n",
      "Epoch: 76/100 | Loss:0.6454\n",
      "Epoch: 77/100 | Loss:0.6454\n",
      "Epoch: 78/100 | Loss:0.6454\n",
      "Epoch: 79/100 | Loss:0.6454\n",
      "Epoch: 80/100 | Loss:0.6454\n",
      "Epoch: 81/100 | Loss:0.6454\n",
      "Epoch: 82/100 | Loss:0.6454\n",
      "Epoch: 83/100 | Loss:0.6454\n",
      "Epoch: 84/100 | Loss:0.6454\n",
      "Epoch: 85/100 | Loss:0.6454\n",
      "Epoch: 86/100 | Loss:0.6454\n",
      "Epoch: 87/100 | Loss:0.6454\n",
      "Epoch: 88/100 | Loss:0.6454\n",
      "Epoch: 89/100 | Loss:0.6454\n",
      "Epoch: 90/100 | Loss:0.6454\n",
      "Epoch: 91/100 | Loss:0.6454\n",
      "Epoch: 92/100 | Loss:0.6454\n",
      "Epoch: 93/100 | Loss:0.6454\n",
      "Epoch: 94/100 | Loss:0.6454\n",
      "Epoch: 95/100 | Loss:0.6454\n",
      "Epoch: 96/100 | Loss:0.6454\n",
      "Epoch: 97/100 | Loss:0.6454\n",
      "Epoch: 98/100 | Loss:0.6454\n",
      "Epoch: 99/100 | Loss:0.6454\n",
      "Epoch: 100/100 | Loss:0.6454\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(f'Epoch: {epoch+1}/100 | Loss:{loss.item():.4f}')\n",
    "    \n",
    "    # Zero gradients, perform a backward pass, and update the weights\n",
    "    optimzier.zero_grad()\n",
    "    loss.backward()\n",
    "    optimzier.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
