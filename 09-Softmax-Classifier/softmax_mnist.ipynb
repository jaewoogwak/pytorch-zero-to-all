{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNIST Model on cpu\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Training MNIST Model on {device}\\n{'=' * 44}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 520)\n",
    "        self.l2 = nn.Linear(520, 320)\n",
    "        self.l3 = nn.Linear(320, 240)\n",
    "        self.l4 = nn.Linear(240, 120)\n",
    "        self.l5 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.308907\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.307937\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.312362\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.297721\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.299137\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.302110\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.304432\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.299421\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.306266\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.300232\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.294275\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.305111\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.294436\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.307254\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.290623\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.294802\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.297317\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.297482\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.295549\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.301259\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.300557\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.294332\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.296040\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.299882\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.297759\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.289875\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.293604\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.299651\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.295833\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.298547\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.293045\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.291708\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.298331\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.287180\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.294888\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.289767\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.281264\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.285476\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.293162\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.281366\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.290778\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.285949\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.294940\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.290358\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.279655\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.276331\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.284565\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.276698\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.273928\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.278800\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.288570\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.276510\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.279399\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.276441\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.267583\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.266772\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.260527\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.260243\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.266070\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.261493\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.257237\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.256505\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.250134\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.241013\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.255866\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.247859\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.253263\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.250095\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.220526\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.223222\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.231006\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.215773\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.213902\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.219691\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.222721\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.151667\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.179972\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.170338\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.137788\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.185875\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.173565\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.108854\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 2.111070\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 2.074434\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 2.082994\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 2.032056\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 2.027043\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 1.955465\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 1.979901\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 1.867795\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 1.672929\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.807355\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.703475\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.707007\n",
      "Training time: 0m 5s\n",
      "===========================\n",
      "Test set: Average loss: 0.0259, Accuracy: 4859/10000 (49%)\n",
      "Testing time: 0m 5s\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 1.642380\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.557875\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.601338\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.538064\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.349941\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.401593\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.228839\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.332789\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.339934\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 1.252388\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.187107\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 1.156519\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 1.148040\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.991034\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 1.069453\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.988967\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 1.211660\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.849444\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 1.049925\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 1.225711\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 1.045117\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.907797\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 1.072910\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.866505\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.860135\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.876708\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.868852\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.853387\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.826726\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.690809\n",
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.856940\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.742232\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.603418\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.754561\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.590036\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.557576\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.514177\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.542123\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.900565\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.720414\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.623369\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.761238\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.679836\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.747935\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.715883\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.795453\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.617076\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.440583\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.719934\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.526699\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.525016\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.510802\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.421152\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.611354\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.573326\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.630532\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.431038\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.727756\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.595445\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.520253\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.418972\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.501994\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.430204\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.537758\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.563663\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.670193\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.335542\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.365707\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.466782\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.440664\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.568663\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.340713\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.351544\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.577632\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.641416\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.454539\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.466803\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.439428\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.379283\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.390821\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.264292\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.387434\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.393187\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.380537\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.422657\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.485785\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.269716\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.481034\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.357655\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.714014\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.338506\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.549999\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.302314\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.309274\n",
      "Training time: 0m 5s\n",
      "===========================\n",
      "Test set: Average loss: 0.0064, Accuracy: 8808/10000 (88%)\n",
      "Testing time: 0m 5s\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.372286\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.303173\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.499947\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.306747\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.406202\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.504418\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.300111\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.644744\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.451050\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.382272\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.460877\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.361506\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.265006\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.579748\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.259405\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.431635\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.387905\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.343650\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.377150\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.409726\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.352599\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.451989\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.333313\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.253297\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.252684\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.349346\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.269790\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.364115\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.278457\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.574419\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.302079\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.259325\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.156194\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.276324\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.314256\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.259061\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.409304\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.420154\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.203414\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.592279\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.336558\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.294894\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.524100\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.355708\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.277765\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.354545\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.249991\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.249738\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.349343\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.283860\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.314930\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.106646\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.313135\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.430030\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.395866\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.515553\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.245416\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.330102\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.277965\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.507123\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.332207\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.426402\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.227875\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.368694\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.303718\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.329343\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.435305\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.432043\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.287600\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.244498\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.264127\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.347525\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.421631\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.385443\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.386176\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.324377\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.277789\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.366378\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.279156\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.255687\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.405010\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.333814\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.558181\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.216695\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.248457\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.213494\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.265545\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.420633\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.162013\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.377634\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.214895\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.437887\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.436518\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.326338\n",
      "Training time: 0m 4s\n",
      "===========================\n",
      "Test set: Average loss: 0.0048, Accuracy: 9074/10000 (91%)\n",
      "Testing time: 0m 5s\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.239324\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.220803\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.300103\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.260380\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.339985\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.244577\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.124996\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.236653\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.242636\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.223003\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.261569\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.336965\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.215719\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.273816\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.518329\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.327597\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.223642\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.324362\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.193656\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.272686\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.420799\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.385227\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.474802\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.289417\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.342858\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.191109\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.370164\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.490926\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.295469\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.551473\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.269837\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.349655\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.255507\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.167331\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.326596\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.220215\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.251220\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.182517\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.220188\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.162644\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.207509\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.458694\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.173397\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.225809\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.233332\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.326243\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.304370\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.243390\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.271837\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.383507\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.348256\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.221382\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.156898\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.125221\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.260474\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.348226\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.252360\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.238910\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.165763\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.250928\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.184392\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.190642\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.182021\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.262934\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.245895\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.125748\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.251686\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.217796\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.343266\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.203676\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.131925\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.247392\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.157083\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.314217\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.153612\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.421272\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.380121\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.103384\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.164729\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.446738\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.184169\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.123484\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.144857\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.160671\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.277321\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.171883\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.288281\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.248423\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.174588\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.152007\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.270581\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.293740\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.175258\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.088655\n",
      "Training time: 0m 4s\n",
      "===========================\n",
      "Test set: Average loss: 0.0034, Accuracy: 9357/10000 (94%)\n",
      "Testing time: 0m 5s\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.170293\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.121040\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.231508\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.128510\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.206684\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.229337\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.279803\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.097418\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.244852\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.317481\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.167757\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.170620\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.211053\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.271688\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.174870\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.419329\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.407920\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.365557\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.246798\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.252991\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.208350\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.211029\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.127954\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.335478\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.107672\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.167509\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.254466\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.380618\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.189199\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.096312\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.122057\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.266905\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.208207\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.175665\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.145730\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.250553\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.264757\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.138132\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.249623\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.226282\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.154195\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.229395\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.163373\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.292136\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.082456\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.110143\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.192598\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.104222\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.217153\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.183499\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.145853\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.204417\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.299948\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.284793\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.089570\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.221586\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.273779\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.154396\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.251917\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.285246\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.084599\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.174181\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.190204\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.235077\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.227251\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.094923\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.304927\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.068926\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.090450\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.398691\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.143677\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.149873\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.148398\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.310180\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.258017\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.074222\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.354625\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.269804\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.113978\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.126005\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.171096\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.129159\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.122560\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.269729\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.195510\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.190305\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.366549\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.235092\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.163196\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.109634\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.173317\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.088130\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.307609\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.255207\n",
      "Training time: 0m 4s\n",
      "===========================\n",
      "Test set: Average loss: 0.0027, Accuracy: 9498/10000 (95%)\n",
      "Testing time: 0m 5s\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.110535\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.134306\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.120837\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.087996\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.095673\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.215617\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.155903\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.078973\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.276214\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.188067\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.060363\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.181249\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.056248\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.114282\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.195795\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.107439\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.170960\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.145106\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.279879\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.098327\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.095491\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.095095\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.164970\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.255425\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.177440\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.220581\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.066343\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.160773\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.124938\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.116631\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.274513\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.168662\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.136868\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.106808\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.166740\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.069559\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.198619\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.294154\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.192793\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.073486\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.197707\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.072077\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.195736\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.204308\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.088863\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.073626\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.230425\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.091481\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.106283\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.130598\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.172240\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.189074\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.287077\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.397987\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.094948\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.170740\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.203025\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.174971\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.174824\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.059906\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.218148\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.249449\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.071038\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.186984\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.197641\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.097705\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.138128\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.051046\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.098588\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.054597\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.145226\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.149395\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.084905\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.324786\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.296587\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.198872\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.061207\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.073217\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.221842\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.096208\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.245550\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.152522\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.084908\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.110996\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.270543\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.151517\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.229092\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.085010\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.138002\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.051962\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.167455\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.042790\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.075884\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.176003\n",
      "Training time: 0m 4s\n",
      "===========================\n",
      "Test set: Average loss: 0.0023, Accuracy: 9543/10000 (95%)\n",
      "Testing time: 0m 5s\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.096240\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.084621\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.135302\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.137611\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.041666\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.217074\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.172728\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.219316\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.209433\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.194447\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.271390\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.097138\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.041026\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.106936\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.330478\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.082342\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.183801\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.263497\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.189883\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.230220\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.080964\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.091038\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.235164\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.046782\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.183182\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.096387\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.221089\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.044324\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.142409\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.108317\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.132657\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.087776\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.054403\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.166012\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.085198\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.129528\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.106843\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.064319\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.058802\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.232185\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.125817\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.113984\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.082844\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.125397\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.185838\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.095698\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.045328\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.372311\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.079877\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.152423\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.247623\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.107930\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.056863\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.108749\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.129639\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.041436\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.157711\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.046009\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.069890\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.116400\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.119256\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.274900\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.192715\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.059790\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.113636\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.070124\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.298044\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.106110\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.054731\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.084396\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.244314\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.154159\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.151158\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.036802\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.066468\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.104410\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.120949\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.106249\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.056274\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.069147\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.231087\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.064636\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.143978\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.109879\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.089212\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.023487\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.119043\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.100482\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.065086\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.089518\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.092822\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.086524\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.149040\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.143468\n",
      "Training time: 0m 4s\n",
      "===========================\n",
      "Test set: Average loss: 0.0022, Accuracy: 9578/10000 (96%)\n",
      "Testing time: 0m 5s\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.127086\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.122779\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.051974\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.079037\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.041102\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.096393\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.095301\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.104868\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.051821\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.067862\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.060769\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.266063\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.085101\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.047628\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.101167\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.024597\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.144904\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.177247\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.105118\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.088732\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.093413\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.126949\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.111096\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.122008\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.187026\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.196013\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.143329\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.102600\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.116501\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.066751\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.045517\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.211597\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.040743\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.246219\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.099251\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.144858\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.031363\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.197440\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.180898\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.106121\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.099106\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.025848\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.070004\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.235213\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.057185\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.124914\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.169100\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.049659\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.076202\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.075984\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.033527\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.048603\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.122703\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.107308\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.107732\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.092376\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.062642\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.132299\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.066951\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.071650\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.069274\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.086966\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.044708\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.114994\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.045379\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.053852\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.176028\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.100140\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.025934\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.154356\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.077409\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.130420\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.068410\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.064071\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.060923\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.096299\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.172527\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.017553\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.074123\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.114324\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.102486\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.027638\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.061316\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.049408\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.048791\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.092609\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.172716\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.065950\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.109693\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.070295\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.067195\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.027186\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.136517\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.072635\n",
      "Training time: 0m 4s\n",
      "===========================\n",
      "Test set: Average loss: 0.0017, Accuracy: 9675/10000 (97%)\n",
      "Testing time: 0m 5s\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.099187\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.134452\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.028281\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.105960\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.079454\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.120471\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.043111\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.114892\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.099806\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.022581\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.065882\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.073780\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.122420\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.012457\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.208051\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.098278\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.156446\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.069233\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.071989\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.015197\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.104640\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.118530\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.086584\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.174311\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.103158\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.099234\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.126660\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.027724\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.062284\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.030110\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.096607\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.031740\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.118692\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.101051\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.130410\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.178879\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.146663\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.123945\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.038057\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.059916\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.083277\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.090864\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.124490\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.031626\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.046455\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.045879\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.107914\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.087140\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.040629\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.113905\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.031878\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.057453\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.029608\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.108346\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.139923\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.132572\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.179012\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.395422\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.022196\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.093205\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.116757\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.059121\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.032775\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.117889\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.175981\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.213018\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.032921\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.031232\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.041657\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.065254\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.074050\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.024629\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.113202\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.058296\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.044031\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.113917\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.038688\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.034976\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.184443\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.072827\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.108858\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.078470\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.130469\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.135552\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.121470\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.027369\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.180202\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.080524\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.046071\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.073959\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.099896\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.101882\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.059960\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.164396\n",
      "Training time: 0m 5s\n",
      "===========================\n",
      "Test set: Average loss: 0.0016, Accuracy: 9686/10000 (97%)\n",
      "Testing time: 0m 5s\n",
      "Total Time: 0m 44s\n",
      "Model was trained on cpu!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    since = time.time()\n",
    "    for epoch in range(1, 10):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
    "        test()\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
    "\n",
    "    m, s = divmod(time.time() - since, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
